
/*
+--------------------------------------------------------------------+
|               ____        __             __                        |
|              / __ \____ _/ /_____ ______/ /___ ___  __             |
|             / / / / __ `/ __/ __ `/ ___/ / __ `/ / / /             |
|            / /_/ / /_/ / /_/ /_/ / /__/ / /_/ / /_/ /              |
|           /_____/\__,_/\__/\__,_/\___/_/\__,_/\__, /               |
|           Automating Digital Production      /____/                |
|                                                                    |
|                                                                    |
|   We believe that leveraging data in the design process should     |
|   be a playful and rewarding art. Our products make this           |
|   possible for digital content creators.                           |
|                                                                    |
|   |email                      |web                  |twitter       |
|   |support@dataclay.com       |dataclay.com         |@dataclay     |
|                                                                    |
|   This code is provided to you for your personal or commercial     |
|   use.  However, you must abide by the terms of the MIT            |
|   License: https://opensource.org/licenses/MIT                     |
|                                                                    |
|                                                                    |
|                Copyright 2013-2018 Dataclay, LLC                   |
|                  Licensed under the MIT License                    |
|                                                                    |
+--------------------------------------------------------------------+

|||||||| Description

This application references a data source and uploads output assets
generated by Templater to a cloud-based storage service, then stages
that uploaded asset to a streaming provider and populates the original
data source with a URL to share or embed.

Please be sure to review the README.md file in this folder to
understand how to use this script.

*/

var log               = require('./logger'),
    enums             = require('./constants'),
    async             = require('async'),
    fs                = require('fs'),
    pth               = require('path'),
    nuuid             = require('node-uuid'),
    nopen             = require('open'),
    nurl              = require('url'),
    nutil             = require('util'),
    Q                 = require('q'),
    moment            = require('moment'),
    emoji             = require('node-emoji'),
    config            = require('./config'),
    jw                = require('./jwplatform'),
    gsheet            = require('./gsheet'),
    dcQ               = require('./api'),
    aws               = require('./aws'),
    yt                = require('./youtube'),
    vmo               = require('./vimeo'),
    deploy            = require('./deploy'),
    pad               = require('pad'),
    argv              = require('minimist')(process.argv.slice(2));

log.info("\n\n------- Deploying output on [ " + moment().format('MMMM Do YYYY, h:mm:ss A') + " ] ----------------")

try {

  async.series([

    function(step){

      var conf =  {
                      gcreds           : argv.gcreds_file
                    , jwcreds          : argv.jwcreds_file
                    , awscreds         : argv.awscreds_file
                    , ytcreds          : argv.ytcreds_file
                    , vmocreds         : argv.vmocreds_file
                    , stream_service   : argv.stream_service
                    , stream_authorize : argv.stream_authorize
                    , stream_group     : argv.stream_group
                    , stream_privacy   : argv.stream_privacy
                    , stream_comments  : argv.stream_comments
                    , stream_download  : argv.stream_download
                    , stream_overwrite : argv.stream_overwrite
                    , data_type        : argv.data_type || enums.data.types.GOOGLE
                    , user             : argv.author
                    , data_collection  : argv.worksheet
                    , sheet_key        : argv.sheet_key
                    , data_uri         : argv.data_uri
                    , dclay_user       : argv.dclay_user
                    , dclay_pass       : argv.dclay_pass
                    , data_index       : argv.data_index
                    , data_key         : argv.data_key
                    , start_row        : argv.start_row
                    , end_row          : argv.end_row
                    , asset_loc        : argv.asset_loc
                    , poster_frame     : argv.poster_frame
                    , poster_archive   : argv.poster_archive
                    , poster_ext       : argv.poster_ext || "png"
                    , skip_clip_archive : ((argv.skip_clip_archive ? JSON.parse(argv.skip_clip_archive) : null) || false )
                    , asset_name       : argv.asset_name || null
                    , asset_ext        : argv.asset_ext
                    , preview_info     : { domain : argv.domain_cell, route : argv.route_cell, player_key : argv.player_cell }
                    , player_key       : argv.player_key || null
                    , storage_type     : (argv.storage_service || enums.storage.types.NONE)
                    , storage_region   : argv.s3_region
                    , storage_bucket   : argv.s3_bucket
                    , storage_folder   : argv.s3_folder
                    , broadcast        : argv.broadcast
                    , title            : argv.title
                    , desc             : argv.desc || "null"
                    , bot_enabled      : argv.bot_enabled
                    , stream_url       : argv.stream_url
                  };

      config.get(conf); 
      config.display();
      step();
    },

    config.read_prefs,

    function choose_stream_service(step) {

        log.info("\n\t[ STREAMING SERVICE ]");
        
        if (config.params.video.service == enums.video.services.JWPLATFORM) {
          jw.get(step)
        } else if (config.params.video.service == enums.video.services.YOUTUBE) {
          yt.get(step)
        } else if (config.params.video.service == enums.video.services.VIMEO) {
          vmo.get(step) 
        } else {
          log.info("\n\t\tNo video streaming service selected.");
          step();
        }
        
    },

    function setup_storage(step) {

        log.info("\n\t[ STORAGE SERVICE ]");

        if (config.params.storage.type === enums.storage.types.S3) 
        {
          aws.config(step);
        } else {
            log.info("\n\t\tNo storage service selected.");
            step();
        }

    },

    function get_job(step) {
        
        if (!config.params.user.dclay_user) {
            gsheet.get(step)
        } else {
            step(); //Dataclay Queue does not need to open the data.
        }
        
    },
    
    function process_video(step) {
      
        var p           = config.params,
            sheet_query = null,
            sql         = null;

       if (config.detect_datasource(p.data.url) === enums.data.types.GOOGLE) {  //Google Sheet Datasource

            //Processing discontiguously (Templater Bot) 
            if (!config.is_batch())
            {

                sql = p.fields.index + '=' + p.data.key;
                
                sheet_query = { 
                    'offset' : 1
                  , 'limit'  : 1
                  , 'query'  : sql
                };

            //Processed contiguously (Batch process)
            } else {

              deploy.is_batch = true;

              sheet_query = {
                offset  : (p.batch.start-1),
                limit   : ((p.batch.end) - (p.batch.start))+1,
                //orderby : p.fields.index
              }

            }

            //Retrieve the rows needed to process

            log.info("Sheet query for getting rows\n\n%o", sheet_query);
            gsheet.worksheet.getRows(sheet_query).then((rows, err) => {

                if (err) {
                  log.error("\n\t\tThere was an error:\n\t\t\t%s\n\t\t\tUsing sheet query %j", err, sheet_query);
                  throw err;
                }

                if (config.is_batch()) {
                  deploy.batch(rows, step);
                } else {
                  deploy.single(rows[0], step);
                }
              
            });

       } else {  //API Data Source

            dcQ.get_job(deploy.single, step);

       }

    }

  ], function(err) {
    log.info("\n\t[ EXIT ]");
  }); //END MAIN APP ENTRY

} catch (err) {

  log.error(err.message);

}
